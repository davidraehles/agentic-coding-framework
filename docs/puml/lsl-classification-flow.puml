@startuml LSL Classification Flow
!include _standard-style.puml

title ReliableCodingClassifier - Three-Layer Classification System

start

:New Exchange\nReceived;

partition "**Layer 0: Session Filter**" {
  :Check for Session\nContinuation Patterns;
  
  note right
    - "This session is being continued..."
    - Summary structure indicators
    - Conversation boundary detection
  end note
  
  if (Session Continuation\nDetected?) then (yes)
    :Return LOCAL\n(session-filter layer);
    stop
  else (no)
    :Continue to\nKeyword Analysis;
  endif
}

partition "**Layer 1: Keyword Analysis**" {
  :Load Coding Keywords\nDictionary;
  
  note left
    scripts/coding-keywords.json
    - "serena", "codebase"
    - "debug", "implement"
    - "git", "npm", "build"
  end note
  
  :Analyze Content for\nCoding Terms;
  
  :Calculate Keyword\nScore & Confidence;
  
  if (High Confidence\nCoding Match?) then (yes)
    :Return CODING_INFRASTRUCTURE\n(keyword layer, ~1ms);
    stop
  elseif (Clear Non-Coding?) then (yes)
    :Return NOT_CODING\n(keyword layer, ~1ms);
    stop
  else (inconclusive)
    :Continue to\nSemantic Analysis;
  endif
}

partition "**Layer 2: Semantic Analysis**" {
  :Performance Check\n(LLM Available?);
  
  if (Performance\nCritical?) then (yes)
    :Use Cached Result\nor Skip;
  else (no)
    :Send to LLM for\nSemantic Understanding;
    
    note right
      1000-1500ms typical
      Deep content understanding
      Context-aware classification
    end note
    
    :Receive LLM\nClassification;
  endif
  
  :Return Final\nClassification\n(semantic layer);
}

:Performance Monitoring\n& Statistics Update;

:Route Content to\nAppropriate Project;

stop

note bottom
  **Performance Optimization:**
  - Session Filter: <1ms (prevents false positives)
  - Keyword Layer: <1ms (200x faster than semantic)
  - Semantic Layer: 1000-1500ms (only when needed)
  
  **Accuracy:**
  - Session Filter: 100% for continuation messages
  - Keyword Layer: 95% for clear cases
  - Semantic Layer: 98% for edge cases
end note

@enduml
